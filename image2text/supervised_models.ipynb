{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SW6hmDdO9R-y"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S44AmWud9brr",
    "outputId": "d534aea5-623e-4bd6-cffb-282be5a9a63a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xmmw-Rdu9R-5"
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CKmX0-i9R-6"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"kc_house_data.csv\")\n",
    "\n",
    "x_data = df_data['sqft_living'].values.reshape(-1, 1).astype(np.float32)\n",
    "y_data = df_data[\"price\"].values.reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "plt.scatter(x_data, y_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-ZFT1l79R-9"
   },
   "outputs": [],
   "source": [
    "# standard scaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "x_data = std_scaler.fit_transform(x_data)\n",
    "y_data = std_scaler.fit_transform(y_data)\n",
    "\n",
    "plt.scatter(x_data, y_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fkMKJRv9R_A"
   },
   "outputs": [],
   "source": [
    "# minmax scaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "x_data = minmax_scaler.fit_transform(x_data)\n",
    "y_data = minmax_scaler.fit_transform(y_data)\n",
    "\n",
    "plt.scatter(x_data, y_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJ97Ebng9R_D"
   },
   "outputs": [],
   "source": [
    "# robust scaler\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "x_data = robust_scaler.fit_transform(x_data)\n",
    "y_data = robust_scaler.fit_transform(y_data)\n",
    "\n",
    "plt.scatter(x_data, y_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXXgnPHO9R_G"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQzEjAyZ9R_H"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLiH2iA19R_K"
   },
   "outputs": [],
   "source": [
    "class DatasetLinearR(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, x_data, y_data):\n",
    "        'Initialization'\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    \n",
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 8\n",
    "}\n",
    "\n",
    "# Generators\n",
    "training_set = DatasetLinearR(x_train, y_train)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "test_set = DatasetLinearR(x_test, y_test)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dABJumPw9R_P"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3aMo8ow9R_Q"
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.i2o = nn.Linear(x_dim, y_dim, bias=True)\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.i2o(x)\n",
    "    \n",
    "    \n",
    "    def train_(self, training_generator, epochs, lr=0.5):\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for x_data, y_data in training_generator:\n",
    "                y_pred = self.forward(x_data)\n",
    "                loss = self.loss(y_pred, y_data)\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                 print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "                    \n",
    "    def test(self, test_generator):\n",
    "            self.eval()\n",
    "            loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x_data, y_data in test_generator:\n",
    "                    x_data, y_data = x_data, y_data\n",
    "                    y_pred = self.forward(x_data)\n",
    "                    loss += (y_pred - y_data)**2\n",
    "\n",
    "            print('Test Accuracy of the model on the 10000 test images: {} %'.format(loss))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXp3i07C9R_S"
   },
   "outputs": [],
   "source": [
    "params_model = {\n",
    "    \"x_dim\": 1,\n",
    "    \"y_dim\": 1\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    \"training_generator\": training_generator,\n",
    "    \"epochs\": 200,\n",
    "    \"lr\": 0.001\n",
    "}\n",
    "\n",
    "\n",
    "linear_regression = LinearRegression(**params_model)\n",
    "\n",
    "linear_regression.train_(**params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5QOt3w89R_V"
   },
   "outputs": [],
   "source": [
    "y_pred = linear_regression.forward(torch.from_numpy(x_test)).detach().numpy()\n",
    "plt.plot(x_test, y_test, 'ro', label='Original data');\n",
    "plt.plot(x_test, y_pred, label='Fitted line');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXmlK4zm9R_X"
   },
   "outputs": [],
   "source": [
    "linear_regression.i2o.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fo8dLNy09R_a"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lfl4mSHA9R_b"
   },
   "outputs": [],
   "source": [
    "x_data = np.random.uniform(-100, 100, size=(200, 2)).astype(np.float32)\n",
    "theta = np.random.uniform(-5, 5, size=(2,1))\n",
    "y_data = (x_data[:, 1] > (x_data[:, 0] * theta[0] + theta[1])).astype(np.float32)\n",
    "y_data = y_data.reshape(-1, 1)\n",
    "\n",
    "plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data.squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUqAVpe09R_e"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvuxrGcY9R_f"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ma64nZy79R_j"
   },
   "outputs": [],
   "source": [
    "class DatasetLogisticR(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, x_data, y_data):\n",
    "        'Initialization'\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    \n",
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 8\n",
    "}\n",
    "\n",
    "# Generators\n",
    "training_set = DatasetLogisticR(x_train, y_train)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "test_set = DatasetLogisticR(x_test, y_test)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rj3QT5sd9R_n"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhk0R2859R_o"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def  __init__(self, x_dim, y_dim=1):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.i2o = nn.Linear(x_dim, y_dim, bias=True)\n",
    "        self.o_activation = nn.Sigmoid()\n",
    "        self.loss = nn.BCELoss()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.i2o(x))\n",
    "    \n",
    "    \n",
    "    def train_(self, training_generator, epochs, lr=0.5):\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for x_data, y_data in training_generator:\n",
    "                y_pred = self.forward(x_data)\n",
    "                loss = self.loss(y_pred, y_data)\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                 print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuqIHbqF9R_r"
   },
   "outputs": [],
   "source": [
    "params_model = {\n",
    "    \"x_dim\": 2,\n",
    "    \"y_dim\": 1\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    \"training_generator\": training_generator,\n",
    "    \"epochs\": 300,\n",
    "    \"lr\": 0.001\n",
    "}\n",
    "\n",
    "\n",
    "logistic_regression = LogisticRegression(**params_model)\n",
    "\n",
    "logistic_regression.train_(**params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FkACLLz9R_u"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3srBgPow9R_v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9TfZXkD9R_z"
   },
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.forward(torch.from_numpy(x_test)).detach().numpy()\n",
    "\n",
    "# roc score\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cm6odxuB9R_4"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_test[:, 0], x_test[:, 1], c=y_test.squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSQAb6OJ9R_8"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_test[:, 0], x_test[:, 1], c=y_pred.squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjW_jJsz9R_-"
   },
   "outputs": [],
   "source": [
    "logistic_regression.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM3BUc0Y9SAB"
   },
   "source": [
    "# Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HX9Fqojy9SAB"
   },
   "outputs": [],
   "source": [
    "x_data = 10 * np.random.random(size=(10000, 1)) - 3\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = 10*np.sin(x_data) + x_data\n",
    "\n",
    "plt.scatter(x_data, y_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilIwwiw89SAF"
   },
   "outputs": [],
   "source": [
    "x_data = 15 * np.random.random(size=(1000, 1)) - 6\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = 10*x_data**2\n",
    "\n",
    "plt.scatter(x_data, y_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gcl1PKLO9SAH"
   },
   "outputs": [],
   "source": [
    "# minmax scaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "x_data = minmax_scaler.fit_transform(x_data)\n",
    "y_data = minmax_scaler.fit_transform(y_data)\n",
    "\n",
    "plt.scatter(x_data, y_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZlakdhs9SAJ"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_hgKGBG9SAJ"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "denhYv1A9SAL"
   },
   "outputs": [],
   "source": [
    "class DatasetFFNN(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, x_data, y_data):\n",
    "        'Initialization'\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    \n",
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 8\n",
    "}\n",
    "\n",
    "# Generators\n",
    "training_set = DatasetFFNN(x_train, y_train)\n",
    "train_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "test_set = DatasetFFNN(x_test, y_test)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yuFqsFQI9SAO"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hud-0Yxw9SAO"
   },
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim, y_dim, prob):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.i2h = nn.Linear(x_dim, h_dim)\n",
    "        self.h2o = nn.Linear(h_dim, y_dim)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)\n",
    "        self.drop1 = nn.Dropout(p=prob)\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.i2h(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.h2o(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def train_(self, train_generator, epochs, lr=0.5):\n",
    "        self.optim = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for x_data, y_data in train_generator:\n",
    "                y_pred = self.forward(x_data)\n",
    "                loss = self.loss(y_pred, y_data)\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                 print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2tGn8gx9SAR"
   },
   "outputs": [],
   "source": [
    "params_model = {\n",
    "    \"x_dim\": 1,\n",
    "    \"h_dim\": 5,\n",
    "    \"y_dim\": 1,\n",
    "    \"prob\": 0.3\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    \"train_generator\": train_generator,\n",
    "    \"epochs\": 500,\n",
    "    \"lr\": 0.001\n",
    "}\n",
    "\n",
    "    \n",
    "ffnn = FFNN(**params_model)\n",
    "\n",
    "ffnn.train_(**params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ee6INVR9SAU"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mcWetBt9SAV"
   },
   "outputs": [],
   "source": [
    "ffnn.eval()\n",
    "y_pred = ffnn.forward(torch.from_numpy(x_test)).detach().numpy()\n",
    "\n",
    "plt.scatter(x_test, y_pred, label='Fitted line');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rgp6dBa99SAX"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPyL_P9H9SAX"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "WcdFlFJv9SAZ",
    "outputId": "a9db77f4-c118-4883-c924-3c43e89ffd78"
   },
   "outputs": [],
   "source": [
    "train_generator = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        './mnist/', train=True, download=True,\n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ccsknGvCPRQk"
   },
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./mnist/', train=False, download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_generator = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=64, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkrA9wYj9SAh"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, x_channel, b1_channel, b2_channel, b3_dim, y_dim,\n",
    "                 kernel_size_conv, kernel_size_mp, stride_conv, stride_mp,\n",
    "                 padding_conv, prob_dropout):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(x_channel, b1_channel, kernel_size=kernel_size_conv,\n",
    "                      stride=stride_conv, padding=padding_conv),\n",
    "            nn.BatchNorm2d(b1_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=kernel_size_mp, stride=stride_mp))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(b1_channel, b2_channel, kernel_size=kernel_size_conv,\n",
    "                      stride=stride_conv, padding=padding_conv),\n",
    "            nn.BatchNorm2d(b2_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=kernel_size_mp, stride=stride_mp))\n",
    "        self.dropout = nn.Dropout(p=prob_dropout)\n",
    "        self.fc = nn.Linear(7*7*b2_channel, y_dim)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    \n",
    "    def train_(self, train_generator, epochs, lr=0.01):\n",
    "        self.optim = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for x_data, y_data in train_generator:\n",
    "                x_data, y_data = x_data.cuda(), y_data.cuda()\n",
    "                y_pred = self.forward(x_data)\n",
    "                loss = self.loss(y_pred, y_data)\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                 print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "                \n",
    "                \n",
    "    def test(self, test_generator):\n",
    "        self.eval()\n",
    "        acc = 0\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_data, y_data in test_generator:\n",
    "                x_data, y_data = x_data.cuda(), y_data.cuda()\n",
    "                y_pred = self.forward(x_data)\n",
    "                _, labels_pred = torch.max(y_pred.data, 1)\n",
    "                acc += (labels_pred == y_data).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * acc / len(test_generator.dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3PgvtD39SAj"
   },
   "outputs": [],
   "source": [
    "params_model = {\n",
    "    \"x_channel\": 1,\n",
    "    \"b1_channel\": 16,\n",
    "    \"b2_channel\": 32,\n",
    "    \"b3_dim\": 128,\n",
    "    \"y_dim\": 10,\n",
    "    \n",
    "    \"kernel_size_conv\": 5,\n",
    "    \"kernel_size_mp\": 2,\n",
    "    \n",
    "    \"stride_conv\": 1,\n",
    "    \"stride_mp\": 2,\n",
    "    \n",
    "    \"padding_conv\": 2,\n",
    "    \"prob_dropout\": 0.2\n",
    "}\n",
    "\n",
    "params_train = {\n",
    "    \"train_generator\": train_generator,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 0.001\n",
    "}\n",
    "\n",
    "    \n",
    "cnn = ConvNet(**params_model).cuda()\n",
    "\n",
    "# next(cnn.parameters()).is_cuda\n",
    "\n",
    "cnn.train_(**params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzhgIygf9SAl"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DGBp6yr6NIlm",
    "outputId": "f3e8e4ff-3ef0-411e-b4b0-d48b782af4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 8.94 %\n"
     ]
    }
   ],
   "source": [
    "cnn.test(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1HyWQ01fQuE6",
    "outputId": "4c9e23bc-29cf-46e6-edfb-c52fc75d706a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.74 %\n"
     ]
    }
   ],
   "source": [
    "test(cnn, test_generator)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TUqAVpe09R_e",
    "rj3QT5sd9R_n",
    "5FkACLLz9R_u",
    "ZZlakdhs9SAJ",
    "yuFqsFQI9SAO",
    "0ee6INVR9SAU"
   ],
   "name": "supervised_models.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
